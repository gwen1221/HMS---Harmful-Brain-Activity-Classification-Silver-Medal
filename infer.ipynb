{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1891a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-04T15:29:32.571584Z",
     "iopub.status.busy": "2024-04-04T15:29:32.571301Z",
     "iopub.status.idle": "2024-04-04T15:29:54.874149Z",
     "shell.execute_reply": "2024-04-04T15:29:54.873219Z"
    },
    "papermill": {
     "duration": 22.311524,
     "end_time": "2024-04-04T15:29:54.877428",
     "exception": false,
     "start_time": "2024-04-04T15:29:32.565904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pywt, librosa\n",
    "\n",
    "USE_WAVELET = None \n",
    "\n",
    "NAMES = ['LL','LP','RP','RR','LZ','RZ']\n",
    "\n",
    "FEATS = [['Fp1','F7','T3','T5','O1'],\n",
    "         ['Fp1','F3','C3','P3','O1'],\n",
    "         ['Fp2','F8','T4','T6','O2'],\n",
    "         ['Fp2','F4','C4','P4','O2'],\n",
    "         ['Fp1','Fz','Cz','Pz','O1'],\n",
    "         ['Fp2','Fz','Cz','Pz','O2'],\n",
    "        ]\n",
    "\n",
    "\n",
    "# DENOISE FUNCTION\n",
    "def maddest(d, axis=None):\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
    "\n",
    "def denoise(x, wavelet='haar', level=1):    \n",
    "    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "    sigma = (1/0.6745) * maddest(coeff[-level])\n",
    "\n",
    "    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n",
    "    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "\n",
    "    ret=pywt.waverec(coeff, wavelet, mode='per')\n",
    "    \n",
    "    return ret\n",
    "\n",
    "import librosa\n",
    "\n",
    "def spectrogram_from_eeg(parquet_path, display=False):\n",
    "    \n",
    "    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n",
    "    eeg = pd.read_parquet(parquet_path)\n",
    "    middle = (len(eeg)-10_000)//2\n",
    "    eeg = eeg.iloc[middle:middle+10_000]\n",
    "    \n",
    "    # VARIABLE TO HOLD SPECTROGRAM\n",
    "    img = np.zeros((192,768,6),dtype='float32')\n",
    "    \n",
    "    if display: plt.figure(figsize=(10,12))\n",
    "    signals = []\n",
    "    for k in range(6):\n",
    "        COLS = FEATS[k]\n",
    "        \n",
    "        for kk in range(4):\n",
    "        \n",
    "            # COMPUTE PAIR DIFFERENCES\n",
    "            x = eeg[COLS[kk]].values - eeg[COLS[kk+1]].values\n",
    "\n",
    "            # FILL NANS\n",
    "            m = np.nanmean(x)\n",
    "            if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
    "            else: x[:] = 0\n",
    "\n",
    "            # DENOISE\n",
    "            if USE_WAVELET:\n",
    "                x = denoise(x, wavelet=USE_WAVELET)\n",
    "            signals.append(x)\n",
    "\n",
    "            # RAW SPECTROGRAM\n",
    "            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//768, \n",
    "                  n_fft=1024, n_mels=192, fmin=0, fmax=20, win_length=128)\n",
    "\n",
    "            # LOG TRANSFORM\n",
    "            width = (mel_spec.shape[1]//32)*32\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n",
    "\n",
    "            # STANDARDIZE TO -1 TO 1\n",
    "            mel_spec_db = (mel_spec_db+40)/40 \n",
    "            img[:,:,k] += mel_spec_db\n",
    "                \n",
    "        # AVERAGE THE 4 MONTAGE DIFFERENCES\n",
    "        img[:,:,k] /= 4.0\n",
    "        \n",
    "        if display:\n",
    "            plt.subplot(3,2,k+1)\n",
    "            plt.imshow(img[:,:,k],aspect='auto',origin='lower')\n",
    "            plt.title(f'EEG {eeg_id} - Spectrogram {NAMES[k]}')\n",
    "            \n",
    "    if display: \n",
    "        plt.show()\n",
    "        plt.figure(figsize=(10,7))\n",
    "        offset = 0\n",
    "        for k in range(6):\n",
    "            if k>0: offset -= signals[3-k].min()\n",
    "            plt.plot(range(10_000),signals[k]+offset,label=NAMES[3-k])\n",
    "            offset += signals[3-k].max()\n",
    "        plt.legend()\n",
    "        plt.title(f'EEG {eeg_id} Signals')\n",
    "        plt.show()\n",
    "        print(); print('#'*25); print()\n",
    "        \n",
    "    return img\n",
    "\n",
    "class CFG:\n",
    "    base_dir = pathlib.Path(\"/kaggle/input/hms-harmful-brain-activity-classification\")\n",
    "    path_test = base_dir / \"test.csv\"\n",
    "    path_submission = base_dir / \"sample_submission.csv\"\n",
    "    spec_dir = base_dir / \"test_spectrograms\"\n",
    "    model_name = \"tf_efficientnet_b0_ns\"\n",
    "\n",
    "    model_weights = sorted(list(\n",
    "        pathlib.Path(\"zzzzzzz\").glob(\"*ft.pt\")\n",
    "    ))\n",
    "    \n",
    "    print(model_weights)\n",
    "\n",
    "    transform = transforms.Resize((768, 768), antialias=False)\n",
    "    batch_size = 16\n",
    "    label_columns = [\n",
    "        \"seizure_vote\",\n",
    "        \"lpd_vote\",\n",
    "        \"gpd_vote\",\n",
    "        \"lrda_vote\",\n",
    "        \"grda_vote\",\n",
    "        \"other_vote\",\n",
    "    ]\n",
    "test = pd.read_csv(CFG.path_test)\n",
    "submission = pd.read_csv(CFG.path_submission)\n",
    "submission = pd.merge(submission, test, how=\"inner\", on=\"eeg_id\")\n",
    "submission[\"path\"] = submission[\"spectrogram_id\"].map(lambda x: CFG.spec_dir / f\"{x}.parquet\")\n",
    "\n",
    "\n",
    "# READ ALL EEG SPECTROGRAMS\n",
    "PATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/'\n",
    "DISPLAY = 1\n",
    "EEG_IDS2 = test.eeg_id.unique()\n",
    "all_eegs2 = {}\n",
    "\n",
    "print('Converting Test EEG to Spectrograms...'); print()\n",
    "for i,eeg_id in enumerate(EEG_IDS2):\n",
    "        \n",
    "    # CREATE SPECTROGRAM FROM EEG PARQUET\n",
    "    img = spectrogram_from_eeg(f'{PATH2}{eeg_id}.parquet', i<DISPLAY)\n",
    "    all_eegs2[eeg_id] = img\n",
    "    \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "def preprocess(x):\n",
    "    m, s = x.mean(), x.std()\n",
    "    x = (x - m) / (s + 1e-6)\n",
    "    return x\n",
    "\n",
    "def preprocess2(x):\n",
    "    x = np.clip(x, np.exp(-6), np.exp(10))\n",
    "    x = np.log(x)\n",
    "    m, s = x.mean(), x.std()\n",
    "    x = (x - m) / (s + 1e-6)\n",
    "    return x\n",
    "\n",
    "\n",
    "class SpecDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transform=CFG.transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        # input\n",
    "        x = all_eegs2[row.eeg_id]\n",
    "        x = [x[:,:,i+0:i+1] for i in range(6)]\n",
    "        x1 = np.concatenate(x,axis=0)[:,:,0]\n",
    "        x1 = preprocess(x1)\n",
    "        # input\n",
    "        x = pd.read_parquet(row.path)\n",
    "        x = x.fillna(-1).values[:, 1:].T\n",
    "        x2 = preprocess2(x)\n",
    "        x2 = torch.Tensor(x2[None, :])\n",
    "        x2 = np.array(CFG.transform(x2))[0]\n",
    "        x = np.concatenate([x1,x2])\n",
    "\n",
    "        \n",
    "        x = torch.Tensor(x[None, :])\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        # output\n",
    "        y = np.array(row.loc[CFG.label_columns].values, 'float32')\n",
    "        y = torch.Tensor(y)\n",
    "        return x, y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc828eb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T15:29:54.909882Z",
     "iopub.status.busy": "2024-04-04T15:29:54.909402Z",
     "iopub.status.idle": "2024-04-04T15:29:54.916127Z",
     "shell.execute_reply": "2024-04-04T15:29:54.915299Z"
    },
    "papermill": {
     "duration": 0.025018,
     "end_time": "2024-04-04T15:29:54.918033",
     "exception": false,
     "start_time": "2024-04-04T15:29:54.893015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_ds = SpecDataset(df=submission)\n",
    "data_loader = DataLoader(dataset=data_ds, num_workers=os.cpu_count())\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f496816c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T15:29:54.949290Z",
     "iopub.status.busy": "2024-04-04T15:29:54.949031Z",
     "iopub.status.idle": "2024-04-04T15:29:55.233744Z",
     "shell.execute_reply": "2024-04-04T15:29:55.232673Z"
    },
    "papermill": {
     "duration": 0.302766,
     "end_time": "2024-04-04T15:29:55.235825",
     "exception": false,
     "start_time": "2024-04-04T15:29:54.933059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(data_loader))\n",
    "x.shape, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df9a2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T15:29:55.268918Z",
     "iopub.status.busy": "2024-04-04T15:29:55.268577Z",
     "iopub.status.idle": "2024-04-04T15:29:55.908636Z",
     "shell.execute_reply": "2024-04-04T15:29:55.907739Z"
    },
    "papermill": {
     "duration": 0.665505,
     "end_time": "2024-04-04T15:29:55.917383",
     "exception": false,
     "start_time": "2024-04-04T15:29:55.251878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(x[0, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f6e5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T15:29:55.966829Z",
     "iopub.status.busy": "2024-04-04T15:29:55.966458Z",
     "iopub.status.idle": "2024-04-04T15:29:59.473979Z",
     "shell.execute_reply": "2024-04-04T15:29:59.472827Z"
    },
    "papermill": {
     "duration": 3.534798,
     "end_time": "2024-04-04T15:29:59.476119",
     "exception": false,
     "start_time": "2024-04-04T15:29:55.941321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"DEVICE: {DEVICE}\")\n",
    "model = timm.create_model(model_name=CFG.model_name, pretrained=False, num_classes=6, in_chans=1)\n",
    "model.to(DEVICE)\n",
    "num_parameter = sum(x.numel() for x in model.parameters())\n",
    "print(f\"Model has {num_parameter} parameters.\")\n",
    "\n",
    "print(f\"DEVICE: {DEVICE}\")\n",
    "\n",
    "prediction = pd.DataFrame(0.0, columns=CFG.label_columns, index=submission.index)\n",
    "for i, path_weight in enumerate(CFG.model_weights):\n",
    "    print(f\"Model {i}: {path_weight}\")\n",
    "    model.load_state_dict(torch.load(path_weight))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        res = []\n",
    "        for x, y in data_loader:\n",
    "            x = x.to(DEVICE)\n",
    "            pred = model(x)\n",
    "            pred = F.softmax(pred, dim=1)\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "            res.append(pred)\n",
    "        res = np.concatenate(res)\n",
    "        res = pd.DataFrame(res, columns=CFG.label_columns, index=submission.index)\n",
    "\n",
    "        prediction = prediction + res\n",
    "        print(\"\\n\")\n",
    "        \n",
    "prediction = prediction / len(CFG.model_weights)\n",
    "\n",
    "submission[CFG.label_columns] = prediction\n",
    "submission = submission[[\"eeg_id\"] + CFG.label_columns]\n",
    "submission.to_csv(\"submission.csv\", index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b93f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T15:29:59.528762Z",
     "iopub.status.busy": "2024-04-04T15:29:59.528073Z",
     "iopub.status.idle": "2024-04-04T15:29:59.542804Z",
     "shell.execute_reply": "2024-04-04T15:29:59.541959Z"
    },
    "papermill": {
     "duration": 0.042897,
     "end_time": "2024-04-04T15:29:59.544814",
     "exception": false,
     "start_time": "2024-04-04T15:29:59.501917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b19cb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T15:29:59.594826Z",
     "iopub.status.busy": "2024-04-04T15:29:59.594541Z",
     "iopub.status.idle": "2024-04-04T15:29:59.602237Z",
     "shell.execute_reply": "2024-04-04T15:29:59.601474Z"
    },
    "papermill": {
     "duration": 0.035207,
     "end_time": "2024-04-04T15:29:59.604257",
     "exception": false,
     "start_time": "2024-04-04T15:29:59.569050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.iloc[:,-6:].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849c65d",
   "metadata": {
    "papermill": {
     "duration": 0.024219,
     "end_time": "2024-04-04T15:29:59.652677",
     "exception": false,
     "start_time": "2024-04-04T15:29:59.628458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4661503,
     "sourceId": 7973224,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4693290,
     "sourceId": 7991109,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4732785,
     "sourceId": 8029771,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33.253816,
   "end_time": "2024-04-04T15:30:02.966949",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-04T15:29:29.713133",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
